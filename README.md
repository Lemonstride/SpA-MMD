# SpA-MMD: Multi-Modal Dataset for Spondyloarthritis (SpA)

> âš ï¸ **IMPORTANT NOTICE**  
> This repository contains only the **processing scripts**, dataset **format specification**, and project documentation.  
> The **SpA-MMD dataset itself is NOT included here**, is **NOT open-source**, and is protected under  
> **Creative Commons BY-NC-ND 4.0** â€” **non-commercial use only**, **no derivatives**, **no redistribution**.  
>  
> To request dataset access, please contact the authors and sign the **Data Usage Agreement (DUA)**.

---

# ğŸ“˜ Overview

**SpA-MMD** is a *multi-modal pathological gait dataset* for **Spondyloarthritis (SpA)** patients, collected using:

- **RGB camera** (30 FPS)
- **Intel RealSense D455** (RGB, 16-bit depth, IMU)
- **TI mmWave Radar** (IWR6843 / AWR6843)

The dataset is designed for:

- Pathological gait analysis  
- Spinal mobility evaluation  
- Pose & motion estimation  
- Radarâ€“vision fusion  
- Clinical assessment & machine learning research  

This repository includes:

- `process.py` and related tools  
- Dataset folder structure specification  
- Synchronization method  
- Metadata format  
- Licensing and dataset access instructions  

---

# ğŸ“ Dataset Structure (Per Subject â†’ Per Session)

Each subject (SXX) may contain multiple recording sessions.

GaitMultiModalDataset/
â”œâ”€â”€ S01/
â”‚ â”œâ”€â”€ session_01/
â”‚ â”œâ”€â”€ session_02/
â”‚ â””â”€â”€ ...
â”œâ”€â”€ S02/
â””â”€â”€ ...

yaml
Copy code

---

# ğŸ“‚ Session Directory Specification

Each session folder contains **aligned RGB, Depth, IMU, and Radar data**:

session_01/
â”œâ”€â”€ rgb/
â”‚ â””â”€â”€ frame_000001.jpg
â”‚ â””â”€â”€ frame_000002.jpg
â”‚
â”œâ”€â”€ depth/
â”‚ â””â”€â”€ frame_000001.png # 16-bit depth, mm
â”‚ â””â”€â”€ frame_000002.png
â”‚
â”œâ”€â”€ imu/
â”‚ â””â”€â”€ imu.csv # ax, ay, az, gx, gy, gz (aligned to 30fps)
â”‚
â”œâ”€â”€ mmwave/
â”‚ â”œâ”€â”€ raw/ # radar ADC / raw frames
â”‚ â””â”€â”€ pointcloud/ # JSON/PLY
â”‚
â”œâ”€â”€ labels/
â”‚ â”œâ”€â”€ kpt2d/ # 2D keypoints (optional)
â”‚ â”œâ”€â”€ kpt3d/ # 3D keypoints (optional)
â”‚ â”œâ”€â”€ gait_phase/ # HS/TO/stance/swing
â”‚ â””â”€â”€ disease_annotations.json
â”‚
â”œâ”€â”€ calib/
â”‚ â”œâ”€â”€ intrinsics_rgb.json
â”‚ â”œâ”€â”€ intrinsics_d455_color.json
â”‚ â”œâ”€â”€ intrinsics_d455_depth.json
â”‚ â”œâ”€â”€ extrinsics_rgb_to_d455.json
â”‚ â”œâ”€â”€ extrinsics_d455_to_mmwave.json
â”‚ â””â”€â”€ depth_scale.txt
â”‚
â””â”€â”€ session_meta.json

yaml
Copy code

---

# ğŸ¯ Modalities

### **RGB**
- 30 FPS  
- `frame_XXXXX.jpg`

### **Depth (D455)**
- 16-bit PNG (uint16)  
- Unit: **mm**  
- Best format for 3D skeleton, reconstruction, and medical-grade processing  

### **IMU (D455)**
CSV format:

frame,timestamp,ax,ay,az,gx,gy,gz

yaml
Copy code

### **mmWave Radar**
- `raw/*.bin`
- `pointcloud/*.json` or `.ply`

---

# ğŸ•’ Multi-Modal Synchronization (Manual but Reliable)

Since the devices cannot be hardware-synchronized, we use a **standardized physical event**:

# âœ‹ **Synchronization Gesture: Raise-to-Head Motion**
This gesture is visible in **all three modalities**.

### **Procedure (3 seconds):**
1. Stand still for 1 second  
2. Raise both hands above head  
3. Hold (freeze) for 1 second  
4. Lower hands  

### Why this gesture?
- RGB: keypoints move significantly  
- Depth: silhouette expands  
- IMU: acceleration spike  
- Radar: point cloud volume increases  

**We align all modalities to RGB 30 FPS timeline based on the detected peak of this gesture.**

---

# ğŸ“ Calibration (Required for Fusion)

Store all calibration files in:

session/calib/

markdown
Copy code

Includes:

- RGB intrinsics  
- D455 color/depth intrinsics  
- Depth â†’ Color extrinsics  
- RGB â†’ Radar extrinsics (optional)  
- Depth scale  

---

# ğŸ”’ Licensing

### âœ” Code License (scripts)
**MIT License**  
Free to use & modify.

### âœ” Dataset License (data files)
**Creative Commons BY-NC-ND 4.0**

- **BYï¼ˆç½²åï¼‰**  
- **NCï¼ˆéå•†ä¸šç”¨é€”ï¼‰**  
- **NDï¼ˆç¦æ­¢ä¿®æ”¹/è¡ç”Ÿï¼‰**  
- **No redistribution**  

### âœ” Dataset is *NOT* included or open-source
It is distributed **only upon request + signed DUA**.

---

# ğŸ“§ Dataset Access

To obtain SpA-MMD dataset:

1. Email the authors  
2. Sign the **Data Usage Agreement (DUA)**  
3. Receive download link  

Contact: <your-email-here>
Subject: Request for SpA-MMD Dataset Access

yaml
Copy code

---

# ğŸ“š Citation

@dataset{spa_mmd_2025,
title={SpA-MMD: Multi-Modal Dataset for Spondyloarthritis Gait Analysis},
author={Your Name},
year={2025},
description={A synchronized RGBâ€“Depthâ€“IMUâ€“mmWave dataset for pathological gait and spinal mobility assessment.}
}

yaml
Copy code

---

# ğŸ›  Tools in This Repository

- `process.py`: Convert bag files â†’ RGB / Depth / IMU / PointCloud  
- Automatic session folder generation  
- mmWave + D455 + RGB timestamp alignment  
- Depth 16-bit processing utilities  
- Visualization scripts (optional)

---

# ğŸš€ Roadmap

- Add 3D skeleton extraction  
- Add Radar-visual fusion demo  
- Add clinical annotation toolkit  
- Release sample sessions (if allowed by IRB)

---

# â¤ï¸ Acknowledgements

Thanks to all SpA patients and medical collaborators who contributed to this project.
